[["index.html", "STAT 720 - Design of Experiments Day 1 Welcome to STAT 720! 1.1 About this course: 1.2 Learning goals 1.3 On notation 1.4 Why do designed experiments exist? 1.5 The golden rules of designed experiments 1.6 Other concepts in designed experiments 1.7 For tomorrow", " STAT 720 - Design of Experiments Josefina Lacasa Summer 2025 Day 1 Welcome to STAT 720! June 9th, 2025 1.1 About this course: About me About you: library(tidyverse) read.csv(&quot;../../students_STAT_720_C.csv&quot;) %&gt;% ggplot(aes(x = degreeProgram))+ geom_bar(fill = &quot;#B388EB&quot;)+ theme_bw()+ theme(panel.grid.minor = element_blank(), panel.border = element_blank(), axis.title.x = element_blank(), axis.text.x = element_text(angle = 50, vjust = 1, hjust=1)) In rounds: What’s your major, what do you expect to learn? 1.1.1 Logistics Website Syllabus Statistical programming requirements Rough mindmap of the course (on whiteboard) Semester project - design your own experiment. Grades: A (100-89.999999999(!!!)), B (89.99-79.99), C (79.99-69.99), D (69.99-59.99), F (&lt;59.99). Attendance policies Semester projects 1.2 Learning goals By the end of this course, you should be able to: - Be able to identify the treatment design, experiment design, experimental unit and observational unit. - Be able to write the statistical model that corresponds to (simple) designed experiments. - Be able to write the Materials and Methods section in a paper (or thesis) that describes the designed experiment. - Distinguish the benefits/disadvantages of different experiment designs. 1.3 On notation scalars: \\(y\\), \\(\\sigma\\), \\(\\beta_0\\) vectors: \\(\\mathbf{y} \\equiv [y_1, y_2, ..., y_n]&#39;\\), \\(\\boldsymbol{\\beta} \\equiv [\\beta_1, \\beta_2, ..., \\beta_p]&#39;\\), \\(\\boldsymbol{u}\\) matrices: \\(\\mathbf{X}\\), \\(\\Sigma\\) probability distribution: \\(y \\sim N(0, \\sigma^2)\\), \\(\\mathbf{y} \\sim N(\\boldsymbol{0}, \\sigma^2\\mathbf{I})\\). 1.4 Why do designed experiments exist? 1.4.1 Example You want to bake cookies with a certain diameter (to fit the box) and are not sure about the amount of baking powder vs. baking soda. more baking powder = smaller, more cakey cookies more baking soda = larger, crispier cookies How can we estimate the cookie diameter Case A: Bake 3 cookies, each with a different levels of baking powder:baking soda ratio. Case B: - On Monday: Bake 3 cookies, each with a different levels of baking powder:baking soda ratio. - On Tuesday: Bake 3 cookies, each with a different levels of baking powder:baking soda ratio. - On Wednesday: Bake 3 cookies, each with a different levels of baking powder:baking soda ratio. Case C: - On Monday: Bake 3 cookies with the first level of baking powder:baking soda ratio. - On Tuesday: Bake 3 cookies with the second level of baking powder:baking soda ratio. - On Wednesday: Bake 3 cookies with the third level of baking powder:baking soda ratio. Group discussion: which is preferrable? 1.5 The golden rules of designed experiments Randomization Replication Local control 1.6 Other concepts in designed experiments Experimental unit: smallest unit to which a treatment is independently assigned/applied. Observational unit: smallest unit on which observations are made. 1.7 For tomorrow Install R and RStudio. "],["basic-types-of-designed-experiments.html", "Day 2 Basic types of designed experiments 2.1 Announcements 2.2 Review 2.3 Types of designs - the basics 2.4 Skeleton ANOVA tables 2.5 Homeworks", " Day 2 Basic types of designed experiments June 10th, 2025 2.1 Announcements Not sure about your project topic? Schedule a meeting! 2.2 Review Differences between observational data and data generated by controlled experiments. The role of experiment design in causal inference. The golden rules of designed experiments: Randomization Replication Local control (blocking) Experimental unit: smallest unit to which a treatment is independently assigned/applied. Observational unit: smallest unit on which observations are made. 2.3 Types of designs - the basics There are several ways to carry out an experiment. The way we carry out an experiment is important because it will establish the blueprint for how the data are generated. This means that the design will determine what observations are similar to each other. Figure 2.1: A blueprint is to a building what the experimental design is to the data. Source 2.3.1 Completely randomized design (CRD) Blueprint: all experimental units are similar. The only factor driving differences between observations is the treatment (and randomness). \\[\\begin{equation} y_{ij} = \\mu + \\tau_i + \\varepsilon_{ij}, \\end{equation}\\] \\[\\begin{equation} \\varepsilon_{ij} \\sim N(0, \\sigma^2), \\end{equation}\\] where \\(y_{ij}\\) is the \\(j\\)th observation of the \\(i\\)th treatment, \\(\\mu\\) is the overall mean, \\(\\tau_i\\) is the effect of the \\(i\\)th treatment, and \\(\\varepsilon_{ij}\\) is the residual for the \\(j\\)th observation of the \\(i\\)th treatment (i.e., the difference between observed and predicted). Figure 2.2: Schematic description of an experiment with a completely randomized design 2.3.2 Randomized complete block design (RCBD) Blocks are groups of similar experimental units and are large enough to fit each treatment at least once Blueprint: all experimental from the same block are similar to each other. The factors driving differences between observations are the treatment and the blocks (and randomness). \\[\\begin{equation} y_{ijk} = \\mu + \\tau_i + \\rho_j + \\varepsilon_{ijk}, \\end{equation}\\] \\[\\begin{equation} \\varepsilon_{ijk} \\sim N(0, \\sigma^2), \\end{equation}\\] where \\(y_{ij}\\) is the \\(j\\)th observation of the \\(i\\)th treatment, \\(\\mu\\) is the overall mean, \\(\\tau_i\\) is the effect of the \\(i\\)th treatment, \\(\\rho_j\\) is the effect of the \\(j\\)th block, and \\(\\varepsilon_{ij}\\) is the residual for the \\(j\\)th observation of the \\(i\\)th treatment (i.e., the difference between observed and predicted). Figure 2.3: Schematic description of an experiment with a randomized complete block design 2.3.3 Incomplete block design (IBD) Blocks are groups of similar experimental units and are not large enough to fit each treatment at least once Blueprint: all experimental from the same block are similar to each other. The factors driving differences between observations are the treatment and the blocks (and randomness). We will define the model for this design later on, after learning more about mixed models. Figure 2.4: Schematic description of an experiment with an incomplete block design 2.4 Skeleton ANOVA tables The Analysis of Variance (ANOVA) can be considered a special case of a linear model that divides the predictors in bins to evaluate their influence on the response (Gelman 2005). Write the topographical sources of variation Write the treatment sources of variation Degrees of freedom An intuitive approach to degrees of freedom: number of independent values. Whiteboard demo. Combine the combined skeleton ANOVA. 2.4.1 Practice examples Plant breeding. A field has 4 homogeneous regions and is divided into 18 smaller plots. Withing those regions, the researchers have randomly assigned the 18 genotypes being tested in the study. Swine nutrition. A swine facility has 3 rooms containing 12 pens (i.e. 36 total pens), each with 4 pigs (note: pigs are similar across pens in a room). Within each room, 6 feeding treatments are randomly allocated to each pen (i.e. each treatment is repeated twice in each room). data.frame(`Source of variation` = c(&quot;Blocks&quot;, &quot;Treatment&quot;, &quot;Error&quot;, &quot;Total&quot;), df = c(&quot;b-1 = 3-1 = 2&quot;, &quot;t-1 = 6-1 = 5&quot;, &quot;(u-1)*b - (t-1) = (12-1)3 - (5-1) = 28&quot;, &quot;N-1 = 36 - 1 = 35&quot;)) %&gt;% knitr::kable(caption = &quot;ANOVA table for the swine example, where b is the number of blocks, t is the number of treatments, u is the number of experimental units per block, and N is the total number of observations.&quot;) ## Warning in attr(x, &quot;align&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) ## Warning in attr(x, &quot;format&quot;): &#39;xfun::attr()&#39; is deprecated. ## Use &#39;xfun::attr2()&#39; instead. ## See help(&quot;Deprecated&quot;) Table 2.1: ANOVA table for the swine example, where b is the number of blocks, t is the number of treatments, u is the number of experimental units per block, and N is the total number of observations. Source.of.variation df Blocks b-1 = 3-1 = 2 Treatment t-1 = 6-1 = 5 Error (u-1)*b - (t-1) = (12-1)3 - (5-1) = 28 Total N-1 = 36 - 1 = 35 2.5 Homeworks Start reading: Chapter 4 in Messy Data Vol1 (Milliken &amp; Johnson) OR Chapter 2 in GLMM (Stroup, 1st ed) - 1st edition of the GLMM book, until “Complication” Schedule a meeting to discuss your project topic. "],["basic-types-of-designed-experiments-1.html", "Day 3 Basic types of designed experiments 3.1 Review 3.2 Types of designs 3.3 Building an ANOVA skeleton using design (aka topographical) and treatment elements 3.4 Linear model good old friend 3.5 Some Practice 3.6 To do", " Day 3 Basic types of designed experiments June 11th, 2025 3.1 Review Experimental unit The golden rules of designed experiments: Replication Randomization Local control (blocking) 3.2 Types of designs 3.2.1 Completely randomized design (CRD) Figure 3.1: Schematic description of an experiment with a completely randomized design 3.2.2 Randomized complete block design (RCBD) Blocks are groups of similar experimental units and are large enough to fit each treatment at least once Figure 3.2: Schematic description of an experiment with a randomized complete block design 3.3 Building an ANOVA skeleton using design (aka topographical) and treatment elements Table 3.1: Constructing the ANOVA skeleton Table 3.1: Experiment or Topographical Source df Block b-1 - Pens(Block) (u-1)*b Total N-1 Table 3.1: Treatment Source df - Treatment t-1 Parallels N-t Total N-1 Table 3.1: Combined Table Source df Block b-1 Treatment t-1 Pens(Block x Trt) (u-1)*b - (t-1) Total N-1 This way to do an ANOVA is normally considered the “What Would Fisher Do” ANOVA. Sir R.A. Fisher did plenty of his very influential work while he was working at the Rothamsted Agricultural Station! Sir R.A. Fisher 3.4 Linear model good old friend What does “linear” mean? What does “ANOVA” mean? \\[\\begin{equation} y_{ij} = \\mu + \\tau_i + \\varepsilon_{ij}, \\\\ \\varepsilon_{ij} \\sim N(0, \\sigma^2), \\end{equation}\\] OR \\[\\begin{equation} y_{i} = \\beta_0 + x_{1i}\\beta_1 +x_{2i}\\beta_2 + x_{3i}\\beta_3 + \\varepsilon_{i}, \\\\ \\varepsilon_{i} \\sim N(0, \\sigma^2), \\\\ x_{1i} = \\begin{cases} 1, &amp; \\text{if treatment A}\\\\ 0, &amp; \\text{otherwise} \\end{cases} \\\\ x_{2i} = \\begin{cases} 1, &amp; \\text{if treatment B}\\\\ 0, &amp; \\text{otherwise} \\end{cases} \\\\ x_{3i} = \\begin{cases} 1, &amp; \\text{if treatment C}\\\\ 0, &amp; \\text{otherwise} \\end{cases} \\end{equation}\\] OR \\[\\begin{equation} \\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\varepsilon}, \\\\ \\boldsymbol{\\varepsilon} \\sim N(\\boldsymbol{0}, \\sigma^2 \\mathbf{I}), \\\\ \\end{equation}\\] OR \\[\\begin{equation} \\mathbf{y} \\sim N(\\boldsymbol{\\mu}, \\sigma^2 \\mathbf{I}), \\\\ \\boldsymbol{\\mu} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\varepsilon} \\end{equation}\\] 3.4.1 The most common assumptions behind most software Constant variance Independence Normality We can describe the general linear model as \\[\\begin{equation} y_{ij} = \\mu + \\tau_i + \\varepsilon_{ij}, \\end{equation}\\] \\[\\begin{equation} \\varepsilon_{ij} \\sim N(0, \\sigma^2), \\end{equation}\\] where \\(y_{ij}\\) is the \\(j\\)th observation of the \\(i\\)th treatment, \\(\\mu\\) is the overall mean, \\(\\tau_i\\) is the treatment effect of the \\(i\\)th treatment, and \\(\\varepsilon_{ij}\\) is the residual for the \\(j\\)th observation of the \\(i\\)th treatment (i.e., the difference between observed and predicted). The form used to describe the model above is called “Model equation form”. Another way of saying the same is the “Probability distribution form”, where we describe the distribution of \\(y\\) directly. \\[\\begin{equation} y_{ij} \\sim N(\\mu_{ij}, \\sigma^2), \\end{equation}\\] or \\[\\begin{equation} \\mathbf{y} \\sim N(\\mu_{ij}, \\sigma^2). \\end{equation}\\] 3.5 Some Practice Check out this R script to follow along! 3.6 To do Start reading: Chapter 4 in Messy Data Vol1 (Milliken &amp; Johnson) OR Chapter 2 in GLMM (Stroup, 1st ed) - 1st edition of the GLMM book, until “Complication” Schedule a meeting to discuss your project topic. "],["linear-models-anova-shells-applied-to-the-more-basic-experiment-designs.html", "Day 4 Linear models, ANOVA shells applied to the more basic experiment designs 4.1 Review 4.2 Linear models 4.3 Takehomes 4.4 Tomorrow", " Day 4 Linear models, ANOVA shells applied to the more basic experiment designs June 12th, 2025 4.1 Review Mindmap of the course, designed experiments, and the reason behind all these analyses. The golden rules to design experiments: Replication Randomization Local control (blocking) A good set of steps to analyze data that is handed to us: What are the treatment factors? What is the experimental unit? Is it the same as the observational unit? How were the treatments applied? (What is the blueprint of the design/underlying structure?) Building the statistical model: Deterministic component Random component (probability distribution) Estimation Method 4.2 Linear models 4.2.1 The most common model - Assumptions Common assumptions behind the default in most software: Constant variance Independence this is what is affected by the design! Normality We can describe the general linear model as \\[\\begin{equation} y_{ij} = \\mu + \\tau_i + \\varepsilon_{ij}, \\end{equation}\\] \\[\\begin{equation} \\varepsilon_{ij} \\sim N(0, \\sigma^2), \\end{equation}\\] where \\(y_{ij}\\) is the \\(j\\)th observation of the \\(i\\)th treatment, \\(\\mu\\) is the overall mean, \\(\\tau_i\\) is the treatment effect of the \\(i\\)th treatment, and \\(\\varepsilon_{ij}\\) is the residual for the \\(j\\)th observation of the \\(i\\)th treatment (i.e., the difference between observed and predicted). 4.2.2 Connection between this and your classical ANOVA table Recall that under Maximum Likelihood Estimation (MLE) and assuming a normal distribution, the estimates for MLE and Least Squares Estimation (LSE) are equivalent: \\(\\hat\\beta_{MLE} =\\hat\\beta_{LSE}\\). Least Squares means that the estimates (\\(\\hat\\beta\\)) are the ones that minimize \\(\\sum_{i=1}^ny_i-\\bar{y}\\). The SS can be divided into the ones explained by the model and the ones not explained by the model \\(SS_{total} = SS_{model} + SS_{error}\\). The SS can also be expressed dividing it into batches depending of their source of variability. The different SS are then used to get an \\(F\\) value used in the analysis of variance. The SS can also be used to estimate \\(\\sigma^2\\): \\(\\sigma^2 = \\frac{\\sum_{i=1}^n (y_i-\\hat{y_i})^2}{df_e}=\\frac{SS_{error}}{df_e}\\) \\(\\sigma^2 = \\frac{SSR}{df_e}\\) How does \\(\\sigma^2\\) affect inference? Confidence intervals: \\(CI_{95\\%} = \\hat{\\beta_j}\\pm t_{dfe, 1-\\alpha} \\cdot \\widehat{s.e.}(\\hat\\beta_j)\\) \\(\\widehat{s.e.}(\\hat\\beta_j) = \\sqrt{\\frac{\\widehat{\\sigma^2}}{s^2_x (n-1)}}\\) 4.2.3 Sorghum example The data below were generated by an experiment comparing sorghum genotypes (Omer et al., 2015). The data presented here correspond to a randomized complete block design ( design structure) that was performed to study different genotypes. Remember that blocks are assumed to be aproximately homogeneous within. Back to the code we worked on yesterday. Check out the code from class here. 4.3 Takehomes Using the sorghum study, we demonstrated that if the true underlying process was actually represented by blocks (i.e., disjoint areas in the field), library(tidyverse) library(emmeans) library(agridat) library(multcomp) # load data data(&quot;omer.sorghum&quot;) df &lt;- omer.sorghum %&gt;% filter(env == &quot;E3&quot;) options(contrasts = c(&quot;contr.sum&quot;, &quot;contr.poly&quot;)) m_without &lt;- lm(yield ~ gen , data= df) m_with &lt;- lm(yield ~ gen + rep, data= df) 4.3.1 If you don’t include the design elements (blocks), their portion of the variance goes to the error # check residuals df with blocks m_with$df.residual ## [1] 51 summary(m_with)$sigma ## [1] 160.0855 # check df without blocks m_without$df.residual ## [1] 54 summary(m_without)$sigma ## [1] 168.9182 means_with &lt;- emmeans(m_without, ~ gen) means_without &lt;- emmeans(m_with, ~ gen) cld(means_with, method = &quot;sidak&quot;, Letters = letters) ## gen emmean SE df lower.CL upper.CL .group ## G17 285 84.5 54 116 455 a ## G06 315 84.5 54 145 484 ab ## G02 515 84.5 54 346 685 abc ## G12 539 84.5 54 370 708 abc ## G01 582 84.5 54 413 751 abc ## G14 583 84.5 54 414 752 abc ## G16 605 84.5 54 435 774 abcd ## G05 643 84.5 54 474 812 abcd ## G15 647 84.5 54 477 816 abcd ## G11 728 84.5 54 559 897 bcd ## G10 739 84.5 54 569 908 bcd ## G08 741 84.5 54 572 911 bcd ## G04 749 84.5 54 580 919 bcd ## G03 805 84.5 54 636 974 cd ## G09 813 84.5 54 644 982 cd ## G13 825 84.5 54 656 994 cd ## G07 937 84.5 54 768 1106 cd ## G18 1030 84.5 54 861 1199 d ## ## Confidence level used: 0.95 ## P value adjustment: tukey method for comparing a family of 18 estimates ## significance level used: alpha = 0.05 ## NOTE: If two or more means share the same grouping symbol, ## then we cannot show them to be different. ## But we also did not show them to be the same. cld(means_without, method = &quot;sidak&quot;, Letters = letters) ## gen emmean SE df lower.CL upper.CL .group ## G17 285 80 51 125 446 a ## G06 315 80 51 154 475 ab ## G02 515 80 51 355 676 abc ## G12 539 80 51 378 700 abcd ## G01 582 80 51 421 743 abcd ## G14 583 80 51 422 744 abcd ## G16 605 80 51 444 765 abcd ## G05 643 80 51 482 804 abcde ## G15 647 80 51 486 807 abcde ## G11 728 80 51 567 889 bcde ## G10 739 80 51 578 899 cde ## G08 741 80 51 581 902 cde ## G04 749 80 51 589 910 cde ## G03 805 80 51 644 966 cde ## G09 813 80 51 652 974 cde ## G13 825 80 51 664 986 cde ## G07 937 80 51 776 1098 de ## G18 1030 80 51 869 1191 e ## ## Results are averaged over the levels of: rep ## Confidence level used: 0.95 ## P value adjustment: tukey method for comparing a family of 18 estimates ## significance level used: alpha = 0.05 ## NOTE: If two or more means share the same grouping symbol, ## then we cannot show them to be different. ## But we also did not show them to be the same. 4.4 Tomorrow Kahoot for attendance "],["review-organizing-data-and-other-helpful-tips.html", "Day 5 Review, organizing data and other helpful tips 5.1 Kahoot! as review 5.2 Organizing data 5.3 Homework", " Day 5 Review, organizing data and other helpful tips June 13th, 2025 5.1 Kahoot! as review Code on the whiteboard 5.2 Organizing data Data Organization in Spreadsheets Excel sheet 5.3 Homework Homework is posted and due in a week "],["the-treatment-structure.html", "Day 6 The treatment structure 6.1 Announcements 6.2 Review 6.3 Treatment structure 6.4 Where is the treatment structure connected to the statistical model? 6.5 Tomorrow:", " Day 6 The treatment structure June 16th, 2025 6.1 Announcements Homework due this Friday Project proposal due this Friday Next week will be on Zoom 6.2 Review The sources of variability in an experiment: Treatment Logistics, design, topographical 6.3 Treatment structure The treatment structure in an experiment is directly connected to the research question, i.e. what the researchers want to study. 6.3.1 Types of treatment structures One-way treatment structure: a set of \\(t\\) treatments or populations where there is no assumed structure among the treatments. Figure 6.1: Schematic description of an experiment with a one-way treatment structure Two-way treatment structure: a set of treatments constructed by combining the levels or possibilities of two factors. Two-way factorial treatment structure. Figure 6.2: Schematic description of an experiment with a two-way treatment structure Factorial arrangement treatment structure: a set of treatments constructed by combining the levels or possibilities of two or more different factors. Figure 6.3: Schematic description of an experiment with a three-way treatment structure Fractional factorial arrangement treatment structure: only a part, or fraction, of the possible treatment combinations in a factorial arrangement treatment structure. Figure 6.4: Schematic description of an experiment with a two-way fractional treatment structure Factorial arrangement treatment structure with one or more controls. Figure 6.5: Schematic description of an experiment with a two-way treatment structure with two controls Examples on the whiteboard 6.4 Where is the treatment structure connected to the statistical model? Remember: the general advice is to divide the sources of variation into treatment and design (i.e., topographical). Normally, the treatments affect the expected value and the experiment design has created groups of data that were generated together. Those groups are groups of similar data and that’s why we say that they are correlated. For now, we’ll leave said correlation in the residual variance-covariance matrix \\(\\mathbf{R}\\). One-way treatment structure \\[\\mathbf{y} \\sim N(\\boldsymbol{\\mu}, \\mathbf{R}), \\\\ \\mu_{j} = \\mu + \\tau_j \\] Two-way treatment structure \\[\\mathbf{y} \\sim N(\\boldsymbol{\\mu}, \\mathbf{R}), \\\\ \\mu_{jk} = \\mu + \\tau_j + \\rho_k +(\\tau \\rho)_{jk}\\] Factorial treatment structure \\[\\mathbf{y} \\sim N(\\boldsymbol{\\mu}, \\mathbf{R}), \\\\ \\mu_{jkl} = \\mu + \\tau_j + \\rho_k + \\gamma_l +(\\tau \\rho)_{jk}+(\\tau \\gamma)_{jl} + ( \\rho \\gamma)_{kl} + (\\tau \\rho \\gamma)_{jkl}\\] Fractional factorial treatment structure, factorial treatment structure with controls Some version of: \\[\\mathbf{y} \\sim N(\\boldsymbol{\\mu}, \\mathbf{R}), \\\\ \\mu_{jk} = \\mu + \\tau_j + \\rho_k +(\\tau \\rho)_{jk}\\] 6.5 Tomorrow: All this is in Chapter 4 in Milliken and Johnson. "],["what-you-ask-of-a-designed-experiment.html", "Day 7 What you ask of a designed experiment 7.1 Announcements 7.2 Review 7.3 ANOVA 7.4 Setting the stage: Estimated marginal means aka least squares means 7.5 Tomorrow", " Day 7 What you ask of a designed experiment June 17th, 2025 7.1 Announcements Homework due this Friday Project proposal due this Friday Next week will be on Zoom 7.2 Review Pre-selected treatments are usually assumed to affect the expected value. Today we’ll focus on those means of interest. Figure 7.1: Mindmap of the analysis of a designed experiment, from the inception to the end conclusions 7.3 ANOVA Table 7.1: Treatment ANOVA for a one-way treatment structure Source df Treatment t-1 Parallels N-t Total N-1 Table 7.2: Treatment ANOVA for a two-way treatment structure Source df Factor A a-1 Factor B b-1 A x B (a-1)(b-1) Parallels N-(ab) Total N-1 Table 7.3: Treatment ANOVA for a three-way factorial treatment structure Source df Factor A a-1 Factor B b-1 Factor C c-1 A x B (a-1)(b-1) A x C (a-1)(c-1) B x C (b-1)(c-1) A x B x C (a-1)(b-1)(c-1) Parallels N-(abc) Total N-1 7.3.1 In case you were wondering: ANOVA and types of sums of squares Type I SS: ordered Type II SS: conditional on main effects Type III SS: conditional on all effects From SS to test F value, to hypothesis test: \\(F = \\frac{SS_{t}/df_t}{SS_{e}/df_e}\\) 7.4 Setting the stage: Estimated marginal means aka least squares means Sometimes, model coefficients or effects are hard to interpret. In designed experiments, we often use the estimated marginal means or least square means to provide a more interpretable result. Estimated marginal means are the expected mean for a given level of a factor, averaging over the other factors in the model. In R, the estimated marginal means are famously handled with the emmeans package. 7.4.1 Example: Download the R script to follow along! More about estimated marginal means: emmeans website [link] 7.4.2 Discussion What is the risk of making inference over a single treatment factor when the estimated interaction seemed to be relevant to explain variability in the data? Where do the degrees of freedom come from? 7.5 Tomorrow More hands-on practice. Your moment to ask the questions about least square means you’ve always wanted to ask. "],["applied-examples.html", "Day 8 Applied examples 8.1 Announcements 8.2 Applied example for today 8.3 Tomorrow", " Day 8 Applied examples June 18th, 2025 8.1 Announcements Homework due this Friday Project proposal due this Friday Next week will be on Zoom Your moment to ask the questions about mean estimation/multiple comparison you’ve always wanted to know but were too afraid to ask. [Note: I will try to include these in class, but many might be covered in STAT 870] From yesterday: ANOVA SS demo [R script] url &lt;- &quot;https://raw.githubusercontent.com/stat720/summer2025/refs/heads/main/data/blood_study_pigs.csv&quot; df_pigs &lt;- read.csv(url) ## Type I m_intercept.only &lt;- lm(Serum_haptoglobin_mg.dL ~ 1, data = df_pigs) m_Trt.only &lt;- lm(Serum_haptoglobin_mg.dL ~ Trt, data = df_pigs) m_Trt.Day &lt;- lm(Serum_haptoglobin_mg.dL ~ Trt+factor(Day), data = df_pigs) m_Trt.Day.TxD &lt;- lm(Serum_haptoglobin_mg.dL ~ Trt*factor(Day), data = df_pigs) sum(m_intercept.only$residuals^2) ## [1] 212318.2 sum(m_intercept.only$residuals^2) - sum(m_Trt.only$residuals^2) ## [1] 81720.2 sum(m_Trt.only$residuals^2) - sum(m_Trt.Day$residuals^2) ## [1] 69494.52 sum(m_Trt.Day$residuals^2) - sum(m_Trt.Day.TxD$residuals^2) ## [1] 24352.12 sum(m_Trt.Day.TxD$residuals^2) ## [1] 36751.37 anova(m_Trt.Day.TxD) ## Analysis of Variance Table ## ## Response: Serum_haptoglobin_mg.dL ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Trt 5 81720 16344 80.049 &lt; 2.2e-16 *** ## factor(Day) 1 69495 69495 340.369 &lt; 2.2e-16 *** ## Trt:factor(Day) 5 24352 4870 23.854 &lt; 2.2e-16 *** ## Residuals 180 36751 204 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## Type II m_intercept.only &lt;- lm(Serum_haptoglobin_mg.dL ~ 1, data = df_pigs) m_Day.only &lt;- lm(Serum_haptoglobin_mg.dL ~ factor(Day), data = df_pigs) m_Trt.only &lt;- lm(Serum_haptoglobin_mg.dL ~ Trt , data = df_pigs) m_Trt.Day &lt;- lm(Serum_haptoglobin_mg.dL ~ Trt + factor(Day), data = df_pigs) m_Trt.Day.TxD &lt;- lm(Serum_haptoglobin_mg.dL ~ Trt*factor(Day), data = df_pigs) sum(m_intercept.only$residuals^2) ## [1] 212318.2 sum(m_Day.only$residuals^2) - sum(m_Trt.Day$residuals^2) ## [1] 81720.2 sum(m_Trt.only$residuals^2) - sum(m_Trt.Day$residuals^2) ## [1] 69494.52 sum(m_Trt.Day$residuals^2) - sum(m_Trt.Day.TxD$residuals^2) ## [1] 24352.12 sum(m_Trt.Day.TxD$residuals^2) ## [1] 36751.37 car::Anova(m_Trt.Day.TxD, type = 2) ## Anova Table (Type II tests) ## ## Response: Serum_haptoglobin_mg.dL ## Sum Sq Df F value Pr(&gt;F) ## Trt 81720 5 80.049 &lt; 2.2e-16 *** ## factor(Day) 69495 1 340.369 &lt; 2.2e-16 *** ## Trt:factor(Day) 24352 5 23.854 &lt; 2.2e-16 *** ## Residuals 36751 180 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 8.2 Applied example for today R script 8.3 Tomorrow Holiday. Kahoot! on Friday. "],["review-5.html", "Day 9 Review 9.1 Announcements 9.2 Next week", " Day 9 Review June 20th, 2025 9.1 Announcements Homework due today New Homework posted today, due Wednesday, July 2nd. Project proposal due today Next week will be on Zoom Your moment to ask the questions about mean estimation/multiple comparison you’ve always wanted to know but were too afraid to ask. [Note: I will try to include these in class, but many might be covered in STAT 870] 9.2 Next week Zoom classes – we will use the link for the office hours "],["semester-project.html", "Day 10 Semester Project 10.1 Learning objectives 10.2 Partial deadlines", " Day 10 Semester Project Semester projects may deal with any topic that interests you [the student], as long as it is approved by the instructor. Broadly, projects are expected to identify a research problem and develop a designed experiment that is appropriate for solving that problem. Projects consist of a manuscript and a tutorial that describes the research problem, the experiment design and the treatment design. 10.1 Learning objectives Be able to identify an experiment design that is appropriate for answering a given research question and discuss the strengths and weaknesses of that design for answering the question. Be able to write the materials and methods section of a paper/thesis, including the statistical model that corresponds the experiment design. 10.2 Partial deadlines 10.2.1 Project proposal - Due Friday June 20 at 2pm CT Write a page-long project proposal that states your research problem and the objective of your project. An example of an appropriate project proposal can be found here. 10.2.2 Written report - Due Friday July 25 at 2pm CT Submit a manuscript including: Introduction Methods, including a clear and complete description of the statistical model and code Expected results Discussion of strengths and weaknesses 10.2.3 Oral presentation - Somewhere between July 21 - August 1 Prepare a 15 minute presentation of the core aspects of your project. Presentations should include at least: Motivation Methods, including a clear and complete description of the statistical model and code Discussion of strengths and weaknesses 10.2.4 Practical reads Casler, M.D. (2015), Fundamentals of Experimental Design: Guidelines for Designing Successful Experiments. Agronomy Journal, 107: 692-705. https://doi.org/10.2134/agronj2013.0114 Casler, M.D. (2018). Power and Replication—Designing Powerful Experiments. In Applied Statistics in Agricultural, Biological, and Environmental Sciences (eds B. Glaz and K.M. Yeater). https://doi.org/10.2134/appliedstatistics.2015.0075.c4 "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
